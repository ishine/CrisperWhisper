{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24982068-48ef-4670-8443-b1326568c103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azureuser/.conda/envs/crisper_whisper/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.09s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'path': '0d38672e0bbdbdc460af55b8bb84a15b2730db2819f2af64f9c777d4d586f2de', 'array': array([0.00238037, 0.0020752 , 0.00198364, ..., 0.00024414, 0.00048828,\n",
      "       0.0005188 ]), 'sampling_rate': 16000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WhisperModel is using WhisperSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True` or `layer_head_mask` not None. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Mister Quilter is the apostle of the middle classes, and we are glad to welcome his gospel. Nor is Mister Quilter is manner less interesting than his matter. He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similes drawn from eating and its results occur most readily to the mind, he has grave doubts whether Sir Frederick Leighton is work is really Greek after all, and can discover in it but little of rocky Ithaca. Lynelle is pictures are a sort of up guards and Adam paintings, and Mason is exquisite. Idols are as national as a jingo poem. Mister Burkett Foster is landscapes smile at one much in the same way that Mister Carker used to flash his teeth, and Mister John Collier gives his sitter a cheerful slap on the back before he says, like a shampooer in a Turkish bath, Next man.', 'chunks': [{'text': 'Mister', 'timestamp': (0.0, 0.78)}, {'text': 'Quilter', 'timestamp': (0.88, 1.22)}, {'text': 'is', 'timestamp': (1.32, 1.38)}, {'text': 'the', 'timestamp': (1.42, 1.52)}, {'text': 'apostle', 'timestamp': (1.62, 2.04)}, {'text': 'of', 'timestamp': (2.16, 2.24)}, {'text': 'the', 'timestamp': (2.3, 2.32)}, {'text': 'middle', 'timestamp': (2.4, 2.58)}, {'text': 'classes,', 'timestamp': (2.74, 3.22)}, {'text': 'and', 'timestamp': (3.32, 3.44)}, {'text': 'we', 'timestamp': (3.48, 3.6)}, {'text': 'are', 'timestamp': (3.62, 3.66)}, {'text': 'glad', 'timestamp': (3.72, 4.04)}, {'text': 'to', 'timestamp': (4.1, 4.18)}, {'text': 'welcome', 'timestamp': (4.26, 4.56)}, {'text': 'his', 'timestamp': (4.64, 4.82)}, {'text': 'gospel.', 'timestamp': (4.9, 5.48)}, {'text': 'Nor', 'timestamp': (6.4, 6.64)}, {'text': 'is', 'timestamp': (6.72, 6.92)}, {'text': 'Mister', 'timestamp': (6.98, 7.2)}, {'text': 'Quilter', 'timestamp': (7.28, 7.6)}, {'text': 'is', 'timestamp': (7.62, 7.68)}, {'text': 'manner', 'timestamp': (7.78, 8.06)}, {'text': 'less', 'timestamp': (8.22, 8.42)}, {'text': 'interesting', 'timestamp': (8.52, 9.08)}, {'text': 'than', 'timestamp': (9.18, 9.36)}, {'text': 'his', 'timestamp': (9.44, 9.66)}, {'text': 'matter.', 'timestamp': (9.82, 10.22)}, {'text': 'He', 'timestamp': (11.16, 11.32)}, {'text': 'tells', 'timestamp': (11.4, 11.64)}, {'text': 'us', 'timestamp': (11.74, 11.94)}, {'text': 'that', 'timestamp': (12.04, 12.24)}, {'text': 'at', 'timestamp': (12.3, 12.44)}, {'text': 'this', 'timestamp': (12.52, 12.68)}, {'text': 'festive', 'timestamp': (12.78, 13.16)}, {'text': 'season', 'timestamp': (13.26, 13.68)}, {'text': 'of', 'timestamp': (13.74, 13.86)}, {'text': 'the', 'timestamp': (13.9, 13.96)}, {'text': 'year,', 'timestamp': (14.04, 14.44)}, {'text': 'with', 'timestamp': (14.82, 15.08)}, {'text': 'Christmas', 'timestamp': (15.16, 15.66)}, {'text': 'and', 'timestamp': (15.72, 15.8)}, {'text': 'roast', 'timestamp': (15.9, 16.16)}, {'text': 'beef', 'timestamp': (16.28, 16.5)}, {'text': 'looming', 'timestamp': (16.64, 16.92)}, {'text': 'before', 'timestamp': (17.0, 17.28)}, {'text': 'us,', 'timestamp': (17.4, 17.72)}, {'text': 'similes', 'timestamp': (18.34, 18.96)}, {'text': 'drawn', 'timestamp': (19.04, 19.26)}, {'text': 'from', 'timestamp': (19.32, 19.46)}, {'text': 'eating', 'timestamp': (19.56, 19.88)}, {'text': 'and', 'timestamp': (19.96, 20.08)}, {'text': 'its', 'timestamp': (20.14, 20.24)}, {'text': 'results', 'timestamp': (20.36, 20.74)}, {'text': 'occur', 'timestamp': (20.84, 21.16)}, {'text': 'most', 'timestamp': (21.26, 21.5)}, {'text': 'readily', 'timestamp': (21.6, 21.92)}, {'text': 'to', 'timestamp': (21.98, 22.1)}, {'text': 'the', 'timestamp': (22.14, 22.22)}, {'text': 'mind,', 'timestamp': (22.3, 22.96)}, {'text': 'he', 'timestamp': (23.52, 23.82)}, {'text': 'has', 'timestamp': (23.88, 24.02)}, {'text': 'grave', 'timestamp': (24.1, 24.38)}, {'text': 'doubts', 'timestamp': (24.46, 24.84)}, {'text': 'whether', 'timestamp': (24.94, 25.26)}, {'text': 'Sir', 'timestamp': (25.36, 25.52)}, {'text': 'Frederick', 'timestamp': (25.62, 25.9)}, {'text': 'Leighton', 'timestamp': (26.02, 26.26)}, {'text': 'is', 'timestamp': (26.34, 26.4)}, {'text': 'work', 'timestamp': (26.48, 26.7)}, {'text': 'is', 'timestamp': (26.8, 26.98)}, {'text': 'really', 'timestamp': (27.06, 27.36)}, {'text': 'Greek', 'timestamp': (27.54, 27.9)}, {'text': 'after', 'timestamp': (28.04, 28.26)}, {'text': 'all,', 'timestamp': (28.42, 28.74)}, {'text': 'and', 'timestamp': (29.22, 29.4)}, {'text': 'can', 'timestamp': (29.46, 29.6)}, {'text': 'discover', 'timestamp': (29.68, 30.04)}, {'text': 'in', 'timestamp': (30.14, 30.28)}, {'text': 'it', 'timestamp': (30.32, 30.48)}, {'text': 'but', 'timestamp': (30.52, 30.66)}, {'text': 'little', 'timestamp': (30.78, 31.02)}, {'text': 'of', 'timestamp': (31.1, 31.36)}, {'text': 'rocky', 'timestamp': (31.54, 31.92)}, {'text': 'Ithaca.', 'timestamp': (32.06, 32.62)}, {'text': 'Lynelle', 'timestamp': (33.64, 33.92)}, {'text': 'is', 'timestamp': (34.06, 34.18)}, {'text': 'pictures', 'timestamp': (34.3, 34.76)}, {'text': 'are', 'timestamp': (34.88, 35.1)}, {'text': 'a', 'timestamp': (35.12, 35.16)}, {'text': 'sort', 'timestamp': (35.22, 35.42)}, {'text': 'of', 'timestamp': (35.46, 35.96)}, {'text': 'up', 'timestamp': (36.06, 36.24)}, {'text': 'guards', 'timestamp': (36.38, 36.64)}, {'text': 'and', 'timestamp': (36.68, 36.78)}, {'text': 'Adam', 'timestamp': (36.88, 37.2)}, {'text': 'paintings,', 'timestamp': (37.44, 38.0)}, {'text': 'and', 'timestamp': (38.4, 38.62)}, {'text': 'Mason', 'timestamp': (38.66, 38.94)}, {'text': 'is', 'timestamp': (38.96, 39.12)}, {'text': 'exquisite.', 'timestamp': (39.22, 39.78)}, {'text': 'Idols', 'timestamp': (39.88, 40.24)}, {'text': 'are', 'timestamp': (40.34, 40.58)}, {'text': 'as', 'timestamp': (40.66, 40.92)}, {'text': 'national', 'timestamp': (41.04, 41.56)}, {'text': 'as', 'timestamp': (41.64, 41.8)}, {'text': 'a', 'timestamp': (41.82, 41.94)}, {'text': 'jingo', 'timestamp': (41.96, 42.36)}, {'text': 'poem.', 'timestamp': (42.48, 42.98)}, {'text': 'Mister', 'timestamp': (44.6, 44.8)}, {'text': 'Burkett', 'timestamp': (44.88, 45.14)}, {'text': 'Foster', 'timestamp': (45.26, 45.6)}, {'text': 'is', 'timestamp': (45.62, 45.72)}, {'text': 'landscapes', 'timestamp': (45.84, 46.42)}, {'text': 'smile', 'timestamp': (46.62, 47.12)}, {'text': 'at', 'timestamp': (47.2, 47.3)}, {'text': 'one', 'timestamp': (47.4, 47.66)}, {'text': 'much', 'timestamp': (47.74, 47.98)}, {'text': 'in', 'timestamp': (48.04, 48.1)}, {'text': 'the', 'timestamp': (48.12, 48.18)}, {'text': 'same', 'timestamp': (48.26, 48.52)}, {'text': 'way', 'timestamp': (48.58, 48.74)}, {'text': 'that', 'timestamp': (48.82, 48.94)}, {'text': 'Mister', 'timestamp': (49.0, 49.22)}, {'text': 'Carker', 'timestamp': (49.36, 49.8)}, {'text': 'used', 'timestamp': (50.18, 50.34)}, {'text': 'to', 'timestamp': (50.38, 50.46)}, {'text': 'flash', 'timestamp': (50.52, 50.84)}, {'text': 'his', 'timestamp': (50.94, 51.06)}, {'text': 'teeth,', 'timestamp': (51.14, 51.68)}, {'text': 'and', 'timestamp': (52.68, 52.94)}, {'text': 'Mister', 'timestamp': (53.0, 53.2)}, {'text': 'John', 'timestamp': (53.26, 53.52)}, {'text': 'Collier', 'timestamp': (53.64, 54.08)}, {'text': 'gives', 'timestamp': (54.4, 54.64)}, {'text': 'his', 'timestamp': (54.7, 54.8)}, {'text': 'sitter', 'timestamp': (54.88, 55.14)}, {'text': 'a', 'timestamp': (55.28, 55.36)}, {'text': 'cheerful', 'timestamp': (55.48, 56.0)}, {'text': 'slap', 'timestamp': (56.12, 56.52)}, {'text': 'on', 'timestamp': (56.6, 56.68)}, {'text': 'the', 'timestamp': (56.72, 56.76)}, {'text': 'back', 'timestamp': (56.88, 57.4)}, {'text': 'before', 'timestamp': (57.58, 57.88)}, {'text': 'he', 'timestamp': (57.92, 58.02)}, {'text': 'says,', 'timestamp': (58.1, 58.46)}, {'text': 'like', 'timestamp': (58.56, 58.7)}, {'text': 'a', 'timestamp': (58.76, 58.92)}, {'text': 'shampooer', 'timestamp': (59.02, 59.68)}, {'text': 'in', 'timestamp': (59.74, 59.84)}, {'text': 'a', 'timestamp': (59.88, 59.96)}, {'text': 'Turkish', 'timestamp': (60.02, 60.34)}, {'text': 'bath,', 'timestamp': (60.46, 60.86)}, {'text': 'Next', 'timestamp': (61.26, 61.58)}, {'text': 'man.', 'timestamp': (61.68, 62.42)}]}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# Ensure transformers module is accessible\n",
    "#transformers_path = os.path.join(os.getcwd(), \"transformers/src\")\n",
    "#sys.path.insert(0, str(transformers_path))\n",
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"/home/azureuser/laurin/code/research/output/crisper_whisper_timestamp_finetuned\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "model.generation_config.median_filter_width=3\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=800,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=1,\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")\n",
    "sample = dataset[0][\"audio\"]\n",
    "print(sample)\n",
    "result = pipe(sample, return_timestamps=\"word\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dbff399-ec94-4b9c-afe9-4a73eb9f63d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1\\n00:00:0.000 --> 00:00:0.780\\nMister\\n\\n2\\n00:00:0.880 --> 00:00:1.220\\nQuilter\\n\\n3\\n00:00:1.320 --> 00:00:1.380\\nis\\n\\n4\\n00:00:1.420 --> 00:00:1.520\\nthe\\n\\n5\\n00:00:1.620 --> 00:00:2.040\\napostle\\n\\n6\\n00:00:2.160 --> 00:00:2.240\\nof\\n\\n7\\n00:00:2.300 --> 00:00:2.320\\nthe\\n\\n8\\n00:00:2.400 --> 00:00:2.580\\nmiddle\\n\\n9\\n00:00:2.740 --> 00:00:3.220\\nclasses,\\n\\n10\\n00:00:3.320 --> 00:00:3.440\\nand\\n\\n11\\n00:00:3.480 --> 00:00:3.600\\nwe\\n\\n12\\n00:00:3.620 --> 00:00:3.660\\nare\\n\\n13\\n00:00:3.720 --> 00:00:4.040\\nglad\\n\\n14\\n00:00:4.100 --> 00:00:4.180\\nto\\n\\n15\\n00:00:4.260 --> 00:00:4.560\\nwelcome\\n\\n16\\n00:00:4.640 --> 00:00:4.820\\nhis\\n\\n17\\n00:00:4.900 --> 00:00:5.480\\ngospel.\\n\\n18\\n00:00:6.400 --> 00:00:6.640\\nNor\\n\\n19\\n00:00:6.720 --> 00:00:6.920\\nis\\n\\n20\\n00:00:6.980 --> 00:00:7.200\\nMister\\n\\n21\\n00:00:7.280 --> 00:00:7.600\\nQuilter\\n\\n22\\n00:00:7.620 --> 00:00:7.680\\nis\\n\\n23\\n00:00:7.780 --> 00:00:8.060\\nmanner\\n\\n24\\n00:00:8.220 --> 00:00:8.420\\nless\\n\\n25\\n00:00:8.520 --> 00:00:9.080\\ninteresting\\n\\n26\\n00:00:9.180 --> 00:00:9.360\\nthan\\n\\n27\\n00:00:9.440 --> 00:00:9.660\\nhis\\n\\n28\\n00:00:9.820 --> 00:00:10.220\\nmatter.\\n\\n29\\n00:00:11.160 --> 00:00:11.320\\nHe\\n\\n30\\n00:00:11.400 --> 00:00:11.640\\ntells\\n\\n31\\n00:00:11.740 --> 00:00:11.940\\nus\\n\\n32\\n00:00:12.040 --> 00:00:12.240\\nthat\\n\\n33\\n00:00:12.300 --> 00:00:12.440\\nat\\n\\n34\\n00:00:12.520 --> 00:00:12.680\\nthis\\n\\n35\\n00:00:12.780 --> 00:00:13.160\\nfestive\\n\\n36\\n00:00:13.260 --> 00:00:13.680\\nseason\\n\\n37\\n00:00:13.740 --> 00:00:13.860\\nof\\n\\n38\\n00:00:13.900 --> 00:00:13.960\\nthe\\n\\n39\\n00:00:14.040 --> 00:00:14.440\\nyear,\\n\\n40\\n00:00:14.820 --> 00:00:15.080\\nwith\\n\\n41\\n00:00:15.160 --> 00:00:15.660\\nChristmas\\n\\n42\\n00:00:15.720 --> 00:00:15.800\\nand\\n\\n43\\n00:00:15.900 --> 00:00:16.160\\nroast\\n\\n44\\n00:00:16.280 --> 00:00:16.500\\nbeef\\n\\n45\\n00:00:16.640 --> 00:00:16.920\\nlooming\\n\\n46\\n00:00:17.000 --> 00:00:17.280\\nbefore\\n\\n47\\n00:00:17.400 --> 00:00:17.720\\nus,\\n\\n48\\n00:00:18.340 --> 00:00:18.960\\nsimiles\\n\\n49\\n00:00:19.040 --> 00:00:19.260\\ndrawn\\n\\n50\\n00:00:19.320 --> 00:00:19.460\\nfrom\\n\\n51\\n00:00:19.560 --> 00:00:19.880\\neating\\n\\n52\\n00:00:19.960 --> 00:00:20.080\\nand\\n\\n53\\n00:00:20.140 --> 00:00:20.240\\nits\\n\\n54\\n00:00:20.360 --> 00:00:20.740\\nresults\\n\\n55\\n00:00:20.840 --> 00:00:21.160\\noccur\\n\\n56\\n00:00:21.260 --> 00:00:21.500\\nmost\\n\\n57\\n00:00:21.600 --> 00:00:21.920\\nreadily\\n\\n58\\n00:00:21.980 --> 00:00:22.100\\nto\\n\\n59\\n00:00:22.140 --> 00:00:22.220\\nthe\\n\\n60\\n00:00:22.300 --> 00:00:22.960\\nmind,\\n\\n61\\n00:00:23.520 --> 00:00:23.820\\nhe\\n\\n62\\n00:00:23.880 --> 00:00:24.020\\nhas\\n\\n63\\n00:00:24.100 --> 00:00:24.380\\ngrave\\n\\n64\\n00:00:24.460 --> 00:00:24.840\\ndoubts\\n\\n65\\n00:00:24.940 --> 00:00:25.260\\nwhether\\n\\n66\\n00:00:25.360 --> 00:00:25.520\\nSir\\n\\n67\\n00:00:25.620 --> 00:00:25.900\\nFrederick\\n\\n68\\n00:00:26.020 --> 00:00:26.260\\nLeighton\\n\\n69\\n00:00:26.340 --> 00:00:26.400\\nis\\n\\n70\\n00:00:26.480 --> 00:00:26.700\\nwork\\n\\n71\\n00:00:26.800 --> 00:00:26.980\\nis\\n\\n72\\n00:00:27.060 --> 00:00:27.360\\nreally\\n\\n73\\n00:00:27.540 --> 00:00:27.900\\nGreek\\n\\n74\\n00:00:28.040 --> 00:00:28.260\\nafter\\n\\n75\\n00:00:28.420 --> 00:00:28.740\\nall,\\n\\n76\\n00:00:29.220 --> 00:00:29.400\\nand\\n\\n77\\n00:00:29.460 --> 00:00:29.600\\ncan\\n\\n78\\n00:00:29.680 --> 00:00:30.040\\ndiscover\\n\\n79\\n00:00:30.140 --> 00:00:30.280\\nin\\n\\n80\\n00:00:30.320 --> 00:00:30.480\\nit\\n\\n81\\n00:00:30.520 --> 00:00:30.660\\nbut\\n\\n82\\n00:00:30.780 --> 00:00:31.020\\nlittle\\n\\n83\\n00:00:31.100 --> 00:00:31.360\\nof\\n\\n84\\n00:00:31.540 --> 00:00:31.920\\nrocky\\n\\n85\\n00:00:32.060 --> 00:00:32.620\\nIthaca.\\n\\n86\\n00:00:33.640 --> 00:00:33.920\\nLynelle\\n\\n87\\n00:00:34.060 --> 00:00:34.180\\nis\\n\\n88\\n00:00:34.300 --> 00:00:34.760\\npictures\\n\\n89\\n00:00:34.880 --> 00:00:35.100\\nare\\n\\n90\\n00:00:35.120 --> 00:00:35.160\\na\\n\\n91\\n00:00:35.220 --> 00:00:35.420\\nsort\\n\\n92\\n00:00:35.460 --> 00:00:35.960\\nof\\n\\n93\\n00:00:36.060 --> 00:00:36.240\\nup\\n\\n94\\n00:00:36.380 --> 00:00:36.640\\nguards\\n\\n95\\n00:00:36.680 --> 00:00:36.780\\nand\\n\\n96\\n00:00:36.880 --> 00:00:37.200\\nAdam\\n\\n97\\n00:00:37.440 --> 00:00:38.000\\npaintings,\\n\\n98\\n00:00:38.400 --> 00:00:38.620\\nand\\n\\n99\\n00:00:38.660 --> 00:00:38.940\\nMason\\n\\n100\\n00:00:38.960 --> 00:00:39.120\\nis\\n\\n101\\n00:00:39.220 --> 00:00:39.780\\nexquisite.\\n\\n102\\n00:00:39.880 --> 00:00:40.240\\nIdols\\n\\n103\\n00:00:40.340 --> 00:00:40.580\\nare\\n\\n104\\n00:00:40.660 --> 00:00:40.920\\nas\\n\\n105\\n00:00:41.040 --> 00:00:41.560\\nnational\\n\\n106\\n00:00:41.640 --> 00:00:41.800\\nas\\n\\n107\\n00:00:41.820 --> 00:00:41.940\\na\\n\\n108\\n00:00:41.960 --> 00:00:42.360\\njingo\\n\\n109\\n00:00:42.480 --> 00:00:42.980\\npoem.\\n\\n110\\n00:00:44.600 --> 00:00:44.800\\nMister\\n\\n111\\n00:00:44.880 --> 00:00:45.140\\nBurkett\\n\\n112\\n00:00:45.260 --> 00:00:45.600\\nFoster\\n\\n113\\n00:00:45.620 --> 00:00:45.720\\nis\\n\\n114\\n00:00:45.840 --> 00:00:46.420\\nlandscapes\\n\\n115\\n00:00:46.620 --> 00:00:47.120\\nsmile\\n\\n116\\n00:00:47.200 --> 00:00:47.300\\nat\\n\\n117\\n00:00:47.400 --> 00:00:47.660\\none\\n\\n118\\n00:00:47.740 --> 00:00:47.980\\nmuch\\n\\n119\\n00:00:48.040 --> 00:00:48.100\\nin\\n\\n120\\n00:00:48.120 --> 00:00:48.180\\nthe\\n\\n121\\n00:00:48.260 --> 00:00:48.520\\nsame\\n\\n122\\n00:00:48.580 --> 00:00:48.740\\nway\\n\\n123\\n00:00:48.820 --> 00:00:48.940\\nthat\\n\\n124\\n00:00:49.000 --> 00:00:49.220\\nMister\\n\\n125\\n00:00:49.360 --> 00:00:49.800\\nCarker\\n\\n126\\n00:00:50.180 --> 00:00:50.340\\nused\\n\\n127\\n00:00:50.380 --> 00:00:50.460\\nto\\n\\n128\\n00:00:50.520 --> 00:00:50.840\\nflash\\n\\n129\\n00:00:50.940 --> 00:00:51.060\\nhis\\n\\n130\\n00:00:51.140 --> 00:00:51.680\\nteeth,\\n\\n131\\n00:00:52.680 --> 00:00:52.940\\nand\\n\\n132\\n00:00:53.000 --> 00:00:53.200\\nMister\\n\\n133\\n00:00:53.260 --> 00:00:53.520\\nJohn\\n\\n134\\n00:00:53.640 --> 00:00:54.080\\nCollier\\n\\n135\\n00:00:54.400 --> 00:00:54.640\\ngives\\n\\n136\\n00:00:54.700 --> 00:00:54.800\\nhis\\n\\n137\\n00:00:54.880 --> 00:00:55.140\\nsitter\\n\\n138\\n00:00:55.280 --> 00:00:55.360\\na\\n\\n139\\n00:00:55.480 --> 00:00:56.000\\ncheerful\\n\\n140\\n00:00:56.120 --> 00:00:56.520\\nslap\\n\\n141\\n00:00:56.600 --> 00:00:56.680\\non\\n\\n142\\n00:00:56.720 --> 00:00:56.760\\nthe\\n\\n143\\n00:00:56.880 --> 00:00:57.400\\nback\\n\\n144\\n00:00:57.580 --> 00:00:57.880\\nbefore\\n\\n145\\n00:00:57.920 --> 00:00:58.020\\nhe\\n\\n146\\n00:00:58.100 --> 00:00:58.460\\nsays,\\n\\n147\\n00:00:58.560 --> 00:00:58.700\\nlike\\n\\n148\\n00:00:58.760 --> 00:00:58.920\\na\\n\\n149\\n00:00:59.020 --> 00:00:59.680\\nshampooer\\n\\n150\\n00:00:59.740 --> 00:00:59.840\\nin\\n\\n151\\n00:00:59.880 --> 00:00:59.960\\na\\n\\n152\\n00:01:0.020 --> 00:01:0.340\\nTurkish\\n\\n153\\n00:01:0.460 --> 00:01:0.860\\nbath,\\n\\n154\\n00:01:1.260 --> 00:01:1.580\\nNext\\n\\n155\\n00:01:1.680 --> 00:01:2.420\\nman.\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def timestamps_to_srt(timestamps):\n",
    "  \"\"\"\n",
    "  Converts a list of timestamps with text data to SubRip (.srt) format string.\n",
    "\n",
    "  Args:\n",
    "      timestamps: A list of dictionaries containing 'text' and 'timestamp' keys.\n",
    "\n",
    "  Returns:\n",
    "      A string containing the subtitle data in SubRip format.\n",
    "  \"\"\"\n",
    "  srt_content = \"\"\n",
    "  # Counter for subtitle line numbers\n",
    "  counter = 1\n",
    "  for word in timestamps:\n",
    "    start_time, end_time = word[\"timestamp\"]\n",
    "    # Format timestamps into hours:minutes:seconds.milliseconds format\n",
    "    start_time_str = f\"{int(start_time // 3600):02d}:{int(start_time // 60 % 60):02d}:{start_time % 60:.03f}\"\n",
    "    end_time_str = f\"{int(end_time // 3600):02d}:{int(end_time // 60 % 60):02d}:{end_time % 60:.03f}\"\n",
    "    \n",
    "    # Add subtitle line with counter, timings, and text\n",
    "    srt_content += f\"{counter}\\n{start_time_str} --> {end_time_str}\\n{word['text']}\\n\\n\"\n",
    "    counter += 1\n",
    "  return srt_content\n",
    "\n",
    "\n",
    "srt_string = timestamps_to_srt(result['chunks'])\n",
    "srt_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cff1f70-5a43-478d-a300-1f0a32b10b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset[0][\"audio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffca2f20-e9a2-49c0-8307-873898f79776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': 'Mister Quilter is the apostle of the middle classes, and we are glad to welcome his gospel. Nor is Mister Quilter is manner less interesting than his matter. He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similes drawn from eating and its results occur most readily to the mind, he has grave doubts whether Sir Frederick Leighton is work is really Greek after all, and can discover in it but little of rocky Ithaca. Lynelle is pictures are a sort of up guards and Adam paintings, and Mason is exquisite. Idols are as national as a jingo poem. Mister Burkett Foster is landscapes smile at one much in the same way that Mister Carker used to flash his teeth, and Mister John Collier gives his sitter a cheerful slap on the back before he says, like a shampooer in a Turkish bath, Next man.',\n",
       " 'chunks': [{'text': 'Mister', 'timestamp': (0.0, 0.78)},\n",
       "  {'text': 'Quilter', 'timestamp': (0.88, 1.22)},\n",
       "  {'text': 'is', 'timestamp': (1.32, 1.38)},\n",
       "  {'text': 'the', 'timestamp': (1.42, 1.52)},\n",
       "  {'text': 'apostle', 'timestamp': (1.62, 2.04)},\n",
       "  {'text': 'of', 'timestamp': (2.16, 2.24)},\n",
       "  {'text': 'the', 'timestamp': (2.3, 2.32)},\n",
       "  {'text': 'middle', 'timestamp': (2.4, 2.58)},\n",
       "  {'text': 'classes,', 'timestamp': (2.74, 3.22)},\n",
       "  {'text': 'and', 'timestamp': (3.32, 3.44)},\n",
       "  {'text': 'we', 'timestamp': (3.48, 3.6)},\n",
       "  {'text': 'are', 'timestamp': (3.62, 3.66)},\n",
       "  {'text': 'glad', 'timestamp': (3.72, 4.04)},\n",
       "  {'text': 'to', 'timestamp': (4.1, 4.18)},\n",
       "  {'text': 'welcome', 'timestamp': (4.26, 4.56)},\n",
       "  {'text': 'his', 'timestamp': (4.64, 4.82)},\n",
       "  {'text': 'gospel.', 'timestamp': (4.9, 5.48)},\n",
       "  {'text': 'Nor', 'timestamp': (6.4, 6.64)},\n",
       "  {'text': 'is', 'timestamp': (6.72, 6.92)},\n",
       "  {'text': 'Mister', 'timestamp': (6.98, 7.2)},\n",
       "  {'text': 'Quilter', 'timestamp': (7.28, 7.6)},\n",
       "  {'text': 'is', 'timestamp': (7.62, 7.68)},\n",
       "  {'text': 'manner', 'timestamp': (7.78, 8.06)},\n",
       "  {'text': 'less', 'timestamp': (8.22, 8.42)},\n",
       "  {'text': 'interesting', 'timestamp': (8.52, 9.08)},\n",
       "  {'text': 'than', 'timestamp': (9.18, 9.36)},\n",
       "  {'text': 'his', 'timestamp': (9.44, 9.66)},\n",
       "  {'text': 'matter.', 'timestamp': (9.82, 10.22)},\n",
       "  {'text': 'He', 'timestamp': (11.16, 11.32)},\n",
       "  {'text': 'tells', 'timestamp': (11.4, 11.64)},\n",
       "  {'text': 'us', 'timestamp': (11.74, 11.94)},\n",
       "  {'text': 'that', 'timestamp': (12.04, 12.24)},\n",
       "  {'text': 'at', 'timestamp': (12.3, 12.44)},\n",
       "  {'text': 'this', 'timestamp': (12.52, 12.68)},\n",
       "  {'text': 'festive', 'timestamp': (12.78, 13.16)},\n",
       "  {'text': 'season', 'timestamp': (13.26, 13.68)},\n",
       "  {'text': 'of', 'timestamp': (13.74, 13.86)},\n",
       "  {'text': 'the', 'timestamp': (13.9, 13.96)},\n",
       "  {'text': 'year,', 'timestamp': (14.04, 14.44)},\n",
       "  {'text': 'with', 'timestamp': (14.82, 15.08)},\n",
       "  {'text': 'Christmas', 'timestamp': (15.16, 15.66)},\n",
       "  {'text': 'and', 'timestamp': (15.72, 15.8)},\n",
       "  {'text': 'roast', 'timestamp': (15.9, 16.16)},\n",
       "  {'text': 'beef', 'timestamp': (16.28, 16.5)},\n",
       "  {'text': 'looming', 'timestamp': (16.64, 16.92)},\n",
       "  {'text': 'before', 'timestamp': (17.0, 17.28)},\n",
       "  {'text': 'us,', 'timestamp': (17.4, 17.72)},\n",
       "  {'text': 'similes', 'timestamp': (18.34, 18.96)},\n",
       "  {'text': 'drawn', 'timestamp': (19.04, 19.26)},\n",
       "  {'text': 'from', 'timestamp': (19.32, 19.46)},\n",
       "  {'text': 'eating', 'timestamp': (19.56, 19.88)},\n",
       "  {'text': 'and', 'timestamp': (19.96, 20.08)},\n",
       "  {'text': 'its', 'timestamp': (20.14, 20.24)},\n",
       "  {'text': 'results', 'timestamp': (20.36, 20.74)},\n",
       "  {'text': 'occur', 'timestamp': (20.84, 21.16)},\n",
       "  {'text': 'most', 'timestamp': (21.26, 21.5)},\n",
       "  {'text': 'readily', 'timestamp': (21.6, 21.92)},\n",
       "  {'text': 'to', 'timestamp': (21.98, 22.1)},\n",
       "  {'text': 'the', 'timestamp': (22.14, 22.22)},\n",
       "  {'text': 'mind,', 'timestamp': (22.3, 22.96)},\n",
       "  {'text': 'he', 'timestamp': (23.52, 23.82)},\n",
       "  {'text': 'has', 'timestamp': (23.88, 24.02)},\n",
       "  {'text': 'grave', 'timestamp': (24.1, 24.38)},\n",
       "  {'text': 'doubts', 'timestamp': (24.46, 24.84)},\n",
       "  {'text': 'whether', 'timestamp': (24.94, 25.26)},\n",
       "  {'text': 'Sir', 'timestamp': (25.36, 25.52)},\n",
       "  {'text': 'Frederick', 'timestamp': (25.62, 25.9)},\n",
       "  {'text': 'Leighton', 'timestamp': (26.02, 26.26)},\n",
       "  {'text': 'is', 'timestamp': (26.34, 26.4)},\n",
       "  {'text': 'work', 'timestamp': (26.48, 26.7)},\n",
       "  {'text': 'is', 'timestamp': (26.8, 26.98)},\n",
       "  {'text': 'really', 'timestamp': (27.06, 27.36)},\n",
       "  {'text': 'Greek', 'timestamp': (27.54, 27.9)},\n",
       "  {'text': 'after', 'timestamp': (28.04, 28.26)},\n",
       "  {'text': 'all,', 'timestamp': (28.42, 28.74)},\n",
       "  {'text': 'and', 'timestamp': (29.22, 29.4)},\n",
       "  {'text': 'can', 'timestamp': (29.46, 29.6)},\n",
       "  {'text': 'discover', 'timestamp': (29.68, 30.04)},\n",
       "  {'text': 'in', 'timestamp': (30.14, 30.28)},\n",
       "  {'text': 'it', 'timestamp': (30.32, 30.48)},\n",
       "  {'text': 'but', 'timestamp': (30.52, 30.66)},\n",
       "  {'text': 'little', 'timestamp': (30.78, 31.02)},\n",
       "  {'text': 'of', 'timestamp': (31.1, 31.36)},\n",
       "  {'text': 'rocky', 'timestamp': (31.54, 31.92)},\n",
       "  {'text': 'Ithaca.', 'timestamp': (32.06, 32.62)},\n",
       "  {'text': 'Lynelle', 'timestamp': (33.64, 33.92)},\n",
       "  {'text': 'is', 'timestamp': (34.06, 34.18)},\n",
       "  {'text': 'pictures', 'timestamp': (34.3, 34.76)},\n",
       "  {'text': 'are', 'timestamp': (34.88, 35.1)},\n",
       "  {'text': 'a', 'timestamp': (35.12, 35.16)},\n",
       "  {'text': 'sort', 'timestamp': (35.22, 35.42)},\n",
       "  {'text': 'of', 'timestamp': (35.46, 35.96)},\n",
       "  {'text': 'up', 'timestamp': (36.06, 36.24)},\n",
       "  {'text': 'guards', 'timestamp': (36.38, 36.64)},\n",
       "  {'text': 'and', 'timestamp': (36.68, 36.78)},\n",
       "  {'text': 'Adam', 'timestamp': (36.88, 37.2)},\n",
       "  {'text': 'paintings,', 'timestamp': (37.44, 38.0)},\n",
       "  {'text': 'and', 'timestamp': (38.4, 38.62)},\n",
       "  {'text': 'Mason', 'timestamp': (38.66, 38.94)},\n",
       "  {'text': 'is', 'timestamp': (38.96, 39.12)},\n",
       "  {'text': 'exquisite.', 'timestamp': (39.22, 39.78)},\n",
       "  {'text': 'Idols', 'timestamp': (39.88, 40.24)},\n",
       "  {'text': 'are', 'timestamp': (40.34, 40.58)},\n",
       "  {'text': 'as', 'timestamp': (40.66, 40.92)},\n",
       "  {'text': 'national', 'timestamp': (41.04, 41.56)},\n",
       "  {'text': 'as', 'timestamp': (41.64, 41.8)},\n",
       "  {'text': 'a', 'timestamp': (41.82, 41.94)},\n",
       "  {'text': 'jingo', 'timestamp': (41.96, 42.36)},\n",
       "  {'text': 'poem.', 'timestamp': (42.48, 42.98)},\n",
       "  {'text': 'Mister', 'timestamp': (44.6, 44.8)},\n",
       "  {'text': 'Burkett', 'timestamp': (44.88, 45.14)},\n",
       "  {'text': 'Foster', 'timestamp': (45.26, 45.6)},\n",
       "  {'text': 'is', 'timestamp': (45.62, 45.72)},\n",
       "  {'text': 'landscapes', 'timestamp': (45.84, 46.42)},\n",
       "  {'text': 'smile', 'timestamp': (46.62, 47.12)},\n",
       "  {'text': 'at', 'timestamp': (47.2, 47.3)},\n",
       "  {'text': 'one', 'timestamp': (47.4, 47.66)},\n",
       "  {'text': 'much', 'timestamp': (47.74, 47.98)},\n",
       "  {'text': 'in', 'timestamp': (48.04, 48.1)},\n",
       "  {'text': 'the', 'timestamp': (48.12, 48.18)},\n",
       "  {'text': 'same', 'timestamp': (48.26, 48.52)},\n",
       "  {'text': 'way', 'timestamp': (48.58, 48.74)},\n",
       "  {'text': 'that', 'timestamp': (48.82, 48.94)},\n",
       "  {'text': 'Mister', 'timestamp': (49.0, 49.22)},\n",
       "  {'text': 'Carker', 'timestamp': (49.36, 49.8)},\n",
       "  {'text': 'used', 'timestamp': (50.18, 50.34)},\n",
       "  {'text': 'to', 'timestamp': (50.38, 50.46)},\n",
       "  {'text': 'flash', 'timestamp': (50.52, 50.84)},\n",
       "  {'text': 'his', 'timestamp': (50.94, 51.06)},\n",
       "  {'text': 'teeth,', 'timestamp': (51.14, 51.68)},\n",
       "  {'text': 'and', 'timestamp': (52.68, 52.94)},\n",
       "  {'text': 'Mister', 'timestamp': (53.0, 53.2)},\n",
       "  {'text': 'John', 'timestamp': (53.26, 53.52)},\n",
       "  {'text': 'Collier', 'timestamp': (53.64, 54.08)},\n",
       "  {'text': 'gives', 'timestamp': (54.4, 54.64)},\n",
       "  {'text': 'his', 'timestamp': (54.7, 54.8)},\n",
       "  {'text': 'sitter', 'timestamp': (54.88, 55.14)},\n",
       "  {'text': 'a', 'timestamp': (55.28, 55.36)},\n",
       "  {'text': 'cheerful', 'timestamp': (55.48, 56.0)},\n",
       "  {'text': 'slap', 'timestamp': (56.12, 56.52)},\n",
       "  {'text': 'on', 'timestamp': (56.6, 56.68)},\n",
       "  {'text': 'the', 'timestamp': (56.72, 56.76)},\n",
       "  {'text': 'back', 'timestamp': (56.88, 57.4)},\n",
       "  {'text': 'before', 'timestamp': (57.58, 57.88)},\n",
       "  {'text': 'he', 'timestamp': (57.92, 58.02)},\n",
       "  {'text': 'says,', 'timestamp': (58.1, 58.46)},\n",
       "  {'text': 'like', 'timestamp': (58.56, 58.7)},\n",
       "  {'text': 'a', 'timestamp': (58.76, 58.92)},\n",
       "  {'text': 'shampooer', 'timestamp': (59.02, 59.68)},\n",
       "  {'text': 'in', 'timestamp': (59.74, 59.84)},\n",
       "  {'text': 'a', 'timestamp': (59.88, 59.96)},\n",
       "  {'text': 'Turkish', 'timestamp': (60.02, 60.34)},\n",
       "  {'text': 'bath,', 'timestamp': (60.46, 60.86)},\n",
       "  {'text': 'Next', 'timestamp': (61.26, 61.58)},\n",
       "  {'text': 'man.', 'timestamp': (61.68, 62.42)}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(sample['array'], return_timestamps=\"word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a19be2b-5bac-4bd2-8c2b-b093785ae571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/wav2vec2-base-960h and revision 55bb623 (https://huggingface.co/facebook/wav2vec2-base-960h).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/home/azureuser/.conda/envs/crisper_whisper/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2024-05-22 11:59:43.937 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /home/azureuser/.conda/envs/crisper_whisper/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import torchaudio\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "from torchaudio import transforms\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"/home/azureuser/laurin/code/research/output/crisper_whisper_timestamp_finetuned\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "model.generation_config.median_filter_width=3\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=800,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=1,\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "# Initialize the transformer pipeline\n",
    "pipe = pipeline(\"automatic-speech-recognition\")\n",
    "\n",
    "# Define the transcribe function\n",
    "def transcribe(audio_bytes):\n",
    "    sr, y = wavfile.read(audio_bytes)\n",
    "    transform = torchaudio.transforms.Resample(sr, 16000)\n",
    "    waveform = transform(torch.tensor(y).float())\n",
    "    \n",
    "    # Ensure waveform is a numpy array and run through the model\n",
    "    transcription = pipe(waveform.numpy(), return_timestamps=\"word\")\n",
    "    \n",
    "    # Extracting just the transcribed text for simplicity\n",
    "    text = transcription['text'] if 'text' in transcription else \"Transcription failed\"\n",
    "    return text\n",
    "\n",
    "# Streamlit interface\n",
    "st.title(\"Speech to Text Transcription\")\n",
    "st.write(\"Upload an audio file to transcribe it.\")\n",
    "\n",
    "# Upload audio file\n",
    "audio_file = st.file_uploader(\"Upload an audio file\", type=[\"wav\"])\n",
    "\n",
    "if audio_file is not None:\n",
    "    # Display the audio player\n",
    "    st.audio(audio_file)\n",
    "    \n",
    "    # Perform transcription\n",
    "    transcription = transcribe(audio_file)\n",
    "    \n",
    "    # Display the transcription result\n",
    "    st.write(\"Transcription:\")\n",
    "    st.write(transcription)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b51c736-a761-41b9-bbdf-d314b19dc215",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crisper_whisper_env",
   "language": "python",
   "name": "crisper_whisper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
